{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm \n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have loaded MNIST data into X_train (images) and y_train (labels)\n",
    "# You need to preprocess the data (e.g., flatten images and one-hot encode labels) before using it\n",
    "\n",
    "# train(X_train, y_train, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pd = pd.read_csv('./train.csv')\n",
    "test_data_pd = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data_pd)\n",
    "test_data = np.array(test_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data[:, :1]\n",
    "\n",
    "train_data = train_data[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x143861e80>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 95\n",
    "plt.title((train_label[index]))\n",
    "plt.imshow(train_data[index].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/np.max(train_data)\n",
    "test_data = test_data/np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_data))\n",
    "print(np.max(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lables_OH = np.zeros((train_data.shape[0], 10))\n",
    "train_lables_OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lable in enumerate(train_label):\n",
    "    # print(i, lable)\n",
    "    train_lables_OH[i][lable] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_lables_OH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ReLU activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Define the derivative of the ReLU activation function\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(x):\n",
    "    exp_vals = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_vals / np.sum(exp_vals, axis=-1, keepdims=True)\n",
    "\n",
    "# Define the categorical cross-entropy loss function\n",
    "def categorical_cross_entropy(y_pred, y_true):\n",
    "    num_samples = y_pred.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-15)) / num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and biases\n",
    "input_size = 784  # MNIST image size (28x28)\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "def forward_pass(X):\n",
    "    global W1, b1, W2, b2\n",
    "    # Input layer to hidden layer\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    # Hidden layer to output layer\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return a1, a2\n",
    "\n",
    "# Backward pass\n",
    "def backward_pass(X, y_true, a1, a2):\n",
    "    global W1, b1, W2, b2\n",
    "    num_samples = X.shape[0]\n",
    "    # Compute gradients for output layer\n",
    "    dz2 = (a2 - y_true) / num_samples\n",
    "    dW2 = np.dot(a1.T, dz2)\n",
    "    db2 = np.sum(dz2, axis=0)\n",
    "    # Compute gradients for hidden layer\n",
    "    da1 = np.dot(dz2, W2.T)\n",
    "    dz1 = da1 * relu_derivative(a1)\n",
    "    dW1 = np.dot(X.T, dz1)\n",
    "    db1 = np.sum(dz1, axis=0)\n",
    "    # Update weights and biases\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(X_train, y_train, epochs, batch_size):\n",
    "    num_samples = X_train.shape[0]\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            # Forward pass\n",
    "            a1, a2 = forward_pass(X_batch)\n",
    "            # Backward pass\n",
    "            backward_pass(X_batch, y_batch, a1, a2)\n",
    "        # Compute training loss\n",
    "        _, y_pred = forward_pass(X_train)\n",
    "        loss = categorical_cross_entropy(y_pred, y_train)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 1.3683\n",
      "Epoch 2/500, Loss: 1.3656\n",
      "Epoch 3/500, Loss: 1.3629\n",
      "Epoch 4/500, Loss: 1.3603\n",
      "Epoch 5/500, Loss: 1.3576\n",
      "Epoch 6/500, Loss: 1.3550\n",
      "Epoch 7/500, Loss: 1.3523\n",
      "Epoch 8/500, Loss: 1.3497\n",
      "Epoch 9/500, Loss: 1.3471\n",
      "Epoch 10/500, Loss: 1.3445\n",
      "Epoch 11/500, Loss: 1.3419\n",
      "Epoch 12/500, Loss: 1.3393\n",
      "Epoch 13/500, Loss: 1.3367\n",
      "Epoch 14/500, Loss: 1.3342\n",
      "Epoch 15/500, Loss: 1.3316\n",
      "Epoch 16/500, Loss: 1.3291\n",
      "Epoch 17/500, Loss: 1.3266\n",
      "Epoch 18/500, Loss: 1.3240\n",
      "Epoch 19/500, Loss: 1.3215\n",
      "Epoch 20/500, Loss: 1.3190\n",
      "Epoch 21/500, Loss: 1.3165\n",
      "Epoch 22/500, Loss: 1.3141\n",
      "Epoch 23/500, Loss: 1.3116\n",
      "Epoch 24/500, Loss: 1.3091\n",
      "Epoch 25/500, Loss: 1.3067\n",
      "Epoch 26/500, Loss: 1.3042\n",
      "Epoch 27/500, Loss: 1.3018\n",
      "Epoch 28/500, Loss: 1.2993\n",
      "Epoch 29/500, Loss: 1.2969\n",
      "Epoch 30/500, Loss: 1.2945\n",
      "Epoch 31/500, Loss: 1.2921\n",
      "Epoch 32/500, Loss: 1.2897\n",
      "Epoch 33/500, Loss: 1.2873\n",
      "Epoch 34/500, Loss: 1.2850\n",
      "Epoch 35/500, Loss: 1.2826\n",
      "Epoch 36/500, Loss: 1.2803\n",
      "Epoch 37/500, Loss: 1.2779\n",
      "Epoch 38/500, Loss: 1.2756\n",
      "Epoch 39/500, Loss: 1.2732\n",
      "Epoch 40/500, Loss: 1.2709\n",
      "Epoch 41/500, Loss: 1.2686\n",
      "Epoch 42/500, Loss: 1.2663\n",
      "Epoch 43/500, Loss: 1.2640\n",
      "Epoch 44/500, Loss: 1.2618\n",
      "Epoch 45/500, Loss: 1.2595\n",
      "Epoch 46/500, Loss: 1.2572\n",
      "Epoch 47/500, Loss: 1.2550\n",
      "Epoch 48/500, Loss: 1.2527\n",
      "Epoch 49/500, Loss: 1.2505\n",
      "Epoch 50/500, Loss: 1.2483\n",
      "Epoch 51/500, Loss: 1.2460\n",
      "Epoch 52/500, Loss: 1.2438\n",
      "Epoch 53/500, Loss: 1.2416\n",
      "Epoch 54/500, Loss: 1.2394\n",
      "Epoch 55/500, Loss: 1.2373\n",
      "Epoch 56/500, Loss: 1.2351\n",
      "Epoch 57/500, Loss: 1.2329\n",
      "Epoch 58/500, Loss: 1.2307\n",
      "Epoch 59/500, Loss: 1.2286\n",
      "Epoch 60/500, Loss: 1.2264\n",
      "Epoch 61/500, Loss: 1.2243\n",
      "Epoch 62/500, Loss: 1.2222\n",
      "Epoch 63/500, Loss: 1.2201\n",
      "Epoch 64/500, Loss: 1.2179\n",
      "Epoch 65/500, Loss: 1.2158\n",
      "Epoch 66/500, Loss: 1.2137\n",
      "Epoch 67/500, Loss: 1.2116\n",
      "Epoch 68/500, Loss: 1.2096\n",
      "Epoch 69/500, Loss: 1.2075\n",
      "Epoch 70/500, Loss: 1.2054\n",
      "Epoch 71/500, Loss: 1.2034\n",
      "Epoch 72/500, Loss: 1.2013\n",
      "Epoch 73/500, Loss: 1.1993\n",
      "Epoch 74/500, Loss: 1.1972\n",
      "Epoch 75/500, Loss: 1.1952\n",
      "Epoch 76/500, Loss: 1.1932\n",
      "Epoch 77/500, Loss: 1.1911\n",
      "Epoch 78/500, Loss: 1.1891\n",
      "Epoch 79/500, Loss: 1.1871\n",
      "Epoch 80/500, Loss: 1.1851\n",
      "Epoch 81/500, Loss: 1.1831\n",
      "Epoch 82/500, Loss: 1.1811\n",
      "Epoch 83/500, Loss: 1.1792\n",
      "Epoch 84/500, Loss: 1.1772\n",
      "Epoch 85/500, Loss: 1.1752\n",
      "Epoch 86/500, Loss: 1.1733\n",
      "Epoch 87/500, Loss: 1.1713\n",
      "Epoch 88/500, Loss: 1.1694\n",
      "Epoch 89/500, Loss: 1.1675\n",
      "Epoch 90/500, Loss: 1.1655\n",
      "Epoch 91/500, Loss: 1.1636\n",
      "Epoch 92/500, Loss: 1.1617\n",
      "Epoch 93/500, Loss: 1.1598\n",
      "Epoch 94/500, Loss: 1.1579\n",
      "Epoch 95/500, Loss: 1.1560\n",
      "Epoch 96/500, Loss: 1.1541\n",
      "Epoch 97/500, Loss: 1.1523\n",
      "Epoch 98/500, Loss: 1.1504\n",
      "Epoch 99/500, Loss: 1.1485\n",
      "Epoch 100/500, Loss: 1.1467\n",
      "Epoch 101/500, Loss: 1.1448\n",
      "Epoch 102/500, Loss: 1.1430\n",
      "Epoch 103/500, Loss: 1.1411\n",
      "Epoch 104/500, Loss: 1.1393\n",
      "Epoch 105/500, Loss: 1.1374\n",
      "Epoch 106/500, Loss: 1.1356\n",
      "Epoch 107/500, Loss: 1.1338\n",
      "Epoch 108/500, Loss: 1.1320\n",
      "Epoch 109/500, Loss: 1.1301\n",
      "Epoch 110/500, Loss: 1.1283\n",
      "Epoch 111/500, Loss: 1.1265\n",
      "Epoch 112/500, Loss: 1.1247\n",
      "Epoch 113/500, Loss: 1.1229\n",
      "Epoch 114/500, Loss: 1.1212\n",
      "Epoch 115/500, Loss: 1.1194\n",
      "Epoch 116/500, Loss: 1.1176\n",
      "Epoch 117/500, Loss: 1.1158\n",
      "Epoch 118/500, Loss: 1.1141\n",
      "Epoch 119/500, Loss: 1.1123\n",
      "Epoch 120/500, Loss: 1.1105\n",
      "Epoch 121/500, Loss: 1.1088\n",
      "Epoch 122/500, Loss: 1.1070\n",
      "Epoch 123/500, Loss: 1.1053\n",
      "Epoch 124/500, Loss: 1.1035\n",
      "Epoch 125/500, Loss: 1.1018\n",
      "Epoch 126/500, Loss: 1.1001\n",
      "Epoch 127/500, Loss: 1.0983\n",
      "Epoch 128/500, Loss: 1.0966\n",
      "Epoch 129/500, Loss: 1.0949\n",
      "Epoch 130/500, Loss: 1.0932\n",
      "Epoch 131/500, Loss: 1.0915\n",
      "Epoch 132/500, Loss: 1.0898\n",
      "Epoch 133/500, Loss: 1.0881\n",
      "Epoch 134/500, Loss: 1.0864\n",
      "Epoch 135/500, Loss: 1.0847\n",
      "Epoch 136/500, Loss: 1.0830\n",
      "Epoch 137/500, Loss: 1.0814\n",
      "Epoch 138/500, Loss: 1.0797\n",
      "Epoch 139/500, Loss: 1.0780\n",
      "Epoch 140/500, Loss: 1.0763\n",
      "Epoch 141/500, Loss: 1.0747\n",
      "Epoch 142/500, Loss: 1.0730\n",
      "Epoch 143/500, Loss: 1.0714\n",
      "Epoch 144/500, Loss: 1.0697\n",
      "Epoch 145/500, Loss: 1.0681\n",
      "Epoch 146/500, Loss: 1.0665\n",
      "Epoch 147/500, Loss: 1.0648\n",
      "Epoch 148/500, Loss: 1.0632\n",
      "Epoch 149/500, Loss: 1.0616\n",
      "Epoch 150/500, Loss: 1.0600\n",
      "Epoch 151/500, Loss: 1.0584\n",
      "Epoch 152/500, Loss: 1.0568\n",
      "Epoch 153/500, Loss: 1.0552\n",
      "Epoch 154/500, Loss: 1.0536\n",
      "Epoch 155/500, Loss: 1.0520\n",
      "Epoch 156/500, Loss: 1.0505\n",
      "Epoch 157/500, Loss: 1.0489\n",
      "Epoch 158/500, Loss: 1.0473\n",
      "Epoch 159/500, Loss: 1.0457\n",
      "Epoch 160/500, Loss: 1.0442\n",
      "Epoch 161/500, Loss: 1.0426\n",
      "Epoch 162/500, Loss: 1.0411\n",
      "Epoch 163/500, Loss: 1.0395\n",
      "Epoch 164/500, Loss: 1.0380\n",
      "Epoch 165/500, Loss: 1.0364\n",
      "Epoch 166/500, Loss: 1.0349\n",
      "Epoch 167/500, Loss: 1.0334\n",
      "Epoch 168/500, Loss: 1.0319\n",
      "Epoch 169/500, Loss: 1.0303\n",
      "Epoch 170/500, Loss: 1.0288\n",
      "Epoch 171/500, Loss: 1.0273\n",
      "Epoch 172/500, Loss: 1.0258\n",
      "Epoch 173/500, Loss: 1.0243\n",
      "Epoch 174/500, Loss: 1.0228\n",
      "Epoch 175/500, Loss: 1.0213\n",
      "Epoch 176/500, Loss: 1.0198\n",
      "Epoch 177/500, Loss: 1.0183\n",
      "Epoch 178/500, Loss: 1.0168\n",
      "Epoch 179/500, Loss: 1.0153\n",
      "Epoch 180/500, Loss: 1.0139\n",
      "Epoch 181/500, Loss: 1.0124\n",
      "Epoch 182/500, Loss: 1.0109\n",
      "Epoch 183/500, Loss: 1.0095\n",
      "Epoch 184/500, Loss: 1.0080\n",
      "Epoch 185/500, Loss: 1.0066\n",
      "Epoch 186/500, Loss: 1.0051\n",
      "Epoch 187/500, Loss: 1.0037\n",
      "Epoch 188/500, Loss: 1.0022\n",
      "Epoch 189/500, Loss: 1.0008\n",
      "Epoch 190/500, Loss: 0.9993\n",
      "Epoch 191/500, Loss: 0.9979\n",
      "Epoch 192/500, Loss: 0.9965\n",
      "Epoch 193/500, Loss: 0.9951\n",
      "Epoch 194/500, Loss: 0.9936\n",
      "Epoch 195/500, Loss: 0.9922\n",
      "Epoch 196/500, Loss: 0.9908\n",
      "Epoch 197/500, Loss: 0.9894\n",
      "Epoch 198/500, Loss: 0.9880\n",
      "Epoch 199/500, Loss: 0.9866\n",
      "Epoch 200/500, Loss: 0.9852\n",
      "Epoch 201/500, Loss: 0.9838\n",
      "Epoch 202/500, Loss: 0.9824\n",
      "Epoch 203/500, Loss: 0.9810\n",
      "Epoch 204/500, Loss: 0.9797\n",
      "Epoch 205/500, Loss: 0.9783\n",
      "Epoch 206/500, Loss: 0.9769\n",
      "Epoch 207/500, Loss: 0.9755\n",
      "Epoch 208/500, Loss: 0.9742\n",
      "Epoch 209/500, Loss: 0.9728\n",
      "Epoch 210/500, Loss: 0.9715\n",
      "Epoch 211/500, Loss: 0.9701\n",
      "Epoch 212/500, Loss: 0.9688\n",
      "Epoch 213/500, Loss: 0.9674\n",
      "Epoch 214/500, Loss: 0.9661\n",
      "Epoch 215/500, Loss: 0.9647\n",
      "Epoch 216/500, Loss: 0.9634\n",
      "Epoch 217/500, Loss: 0.9621\n",
      "Epoch 218/500, Loss: 0.9607\n",
      "Epoch 219/500, Loss: 0.9594\n",
      "Epoch 220/500, Loss: 0.9581\n",
      "Epoch 221/500, Loss: 0.9568\n",
      "Epoch 222/500, Loss: 0.9555\n",
      "Epoch 223/500, Loss: 0.9542\n",
      "Epoch 224/500, Loss: 0.9529\n",
      "Epoch 225/500, Loss: 0.9516\n",
      "Epoch 226/500, Loss: 0.9503\n",
      "Epoch 227/500, Loss: 0.9490\n",
      "Epoch 228/500, Loss: 0.9477\n",
      "Epoch 229/500, Loss: 0.9464\n",
      "Epoch 230/500, Loss: 0.9451\n",
      "Epoch 231/500, Loss: 0.9438\n",
      "Epoch 232/500, Loss: 0.9425\n",
      "Epoch 233/500, Loss: 0.9413\n",
      "Epoch 234/500, Loss: 0.9400\n",
      "Epoch 235/500, Loss: 0.9387\n",
      "Epoch 236/500, Loss: 0.9374\n",
      "Epoch 237/500, Loss: 0.9362\n",
      "Epoch 238/500, Loss: 0.9349\n",
      "Epoch 239/500, Loss: 0.9337\n",
      "Epoch 240/500, Loss: 0.9324\n",
      "Epoch 241/500, Loss: 0.9311\n",
      "Epoch 242/500, Loss: 0.9299\n",
      "Epoch 243/500, Loss: 0.9287\n",
      "Epoch 244/500, Loss: 0.9274\n",
      "Epoch 245/500, Loss: 0.9262\n",
      "Epoch 246/500, Loss: 0.9249\n",
      "Epoch 247/500, Loss: 0.9237\n",
      "Epoch 248/500, Loss: 0.9225\n",
      "Epoch 249/500, Loss: 0.9212\n",
      "Epoch 250/500, Loss: 0.9200\n",
      "Epoch 251/500, Loss: 0.9188\n",
      "Epoch 252/500, Loss: 0.9175\n",
      "Epoch 253/500, Loss: 0.9163\n",
      "Epoch 254/500, Loss: 0.9151\n",
      "Epoch 255/500, Loss: 0.9139\n",
      "Epoch 256/500, Loss: 0.9127\n",
      "Epoch 257/500, Loss: 0.9115\n",
      "Epoch 258/500, Loss: 0.9103\n",
      "Epoch 259/500, Loss: 0.9091\n",
      "Epoch 260/500, Loss: 0.9079\n",
      "Epoch 261/500, Loss: 0.9067\n",
      "Epoch 262/500, Loss: 0.9055\n",
      "Epoch 263/500, Loss: 0.9043\n",
      "Epoch 264/500, Loss: 0.9031\n",
      "Epoch 265/500, Loss: 0.9019\n",
      "Epoch 266/500, Loss: 0.9007\n",
      "Epoch 267/500, Loss: 0.8995\n",
      "Epoch 268/500, Loss: 0.8983\n",
      "Epoch 269/500, Loss: 0.8972\n",
      "Epoch 270/500, Loss: 0.8960\n",
      "Epoch 271/500, Loss: 0.8948\n",
      "Epoch 272/500, Loss: 0.8936\n",
      "Epoch 273/500, Loss: 0.8925\n",
      "Epoch 274/500, Loss: 0.8913\n",
      "Epoch 275/500, Loss: 0.8901\n",
      "Epoch 276/500, Loss: 0.8890\n",
      "Epoch 277/500, Loss: 0.8878\n",
      "Epoch 278/500, Loss: 0.8867\n",
      "Epoch 279/500, Loss: 0.8855\n",
      "Epoch 280/500, Loss: 0.8844\n",
      "Epoch 281/500, Loss: 0.8832\n",
      "Epoch 282/500, Loss: 0.8821\n",
      "Epoch 283/500, Loss: 0.8809\n",
      "Epoch 284/500, Loss: 0.8798\n",
      "Epoch 285/500, Loss: 0.8787\n",
      "Epoch 286/500, Loss: 0.8775\n",
      "Epoch 287/500, Loss: 0.8764\n",
      "Epoch 288/500, Loss: 0.8753\n",
      "Epoch 289/500, Loss: 0.8741\n",
      "Epoch 290/500, Loss: 0.8730\n",
      "Epoch 291/500, Loss: 0.8719\n",
      "Epoch 292/500, Loss: 0.8708\n",
      "Epoch 293/500, Loss: 0.8697\n",
      "Epoch 294/500, Loss: 0.8685\n",
      "Epoch 295/500, Loss: 0.8674\n",
      "Epoch 296/500, Loss: 0.8663\n",
      "Epoch 297/500, Loss: 0.8652\n",
      "Epoch 298/500, Loss: 0.8641\n",
      "Epoch 299/500, Loss: 0.8630\n",
      "Epoch 300/500, Loss: 0.8619\n",
      "Epoch 301/500, Loss: 0.8608\n",
      "Epoch 302/500, Loss: 0.8597\n",
      "Epoch 303/500, Loss: 0.8586\n",
      "Epoch 304/500, Loss: 0.8575\n",
      "Epoch 305/500, Loss: 0.8564\n",
      "Epoch 306/500, Loss: 0.8554\n",
      "Epoch 307/500, Loss: 0.8543\n",
      "Epoch 308/500, Loss: 0.8532\n",
      "Epoch 309/500, Loss: 0.8521\n",
      "Epoch 310/500, Loss: 0.8510\n",
      "Epoch 311/500, Loss: 0.8500\n",
      "Epoch 312/500, Loss: 0.8489\n",
      "Epoch 313/500, Loss: 0.8478\n",
      "Epoch 314/500, Loss: 0.8467\n",
      "Epoch 315/500, Loss: 0.8457\n",
      "Epoch 316/500, Loss: 0.8446\n",
      "Epoch 317/500, Loss: 0.8436\n",
      "Epoch 318/500, Loss: 0.8425\n",
      "Epoch 319/500, Loss: 0.8414\n",
      "Epoch 320/500, Loss: 0.8404\n",
      "Epoch 321/500, Loss: 0.8393\n",
      "Epoch 322/500, Loss: 0.8383\n",
      "Epoch 323/500, Loss: 0.8372\n",
      "Epoch 324/500, Loss: 0.8362\n",
      "Epoch 325/500, Loss: 0.8352\n",
      "Epoch 326/500, Loss: 0.8341\n",
      "Epoch 327/500, Loss: 0.8331\n",
      "Epoch 328/500, Loss: 0.8321\n",
      "Epoch 329/500, Loss: 0.8310\n",
      "Epoch 330/500, Loss: 0.8300\n",
      "Epoch 331/500, Loss: 0.8290\n",
      "Epoch 332/500, Loss: 0.8279\n",
      "Epoch 333/500, Loss: 0.8269\n",
      "Epoch 334/500, Loss: 0.8259\n",
      "Epoch 335/500, Loss: 0.8249\n",
      "Epoch 336/500, Loss: 0.8238\n",
      "Epoch 337/500, Loss: 0.8228\n",
      "Epoch 338/500, Loss: 0.8218\n",
      "Epoch 339/500, Loss: 0.8208\n",
      "Epoch 340/500, Loss: 0.8198\n",
      "Epoch 341/500, Loss: 0.8188\n",
      "Epoch 342/500, Loss: 0.8178\n",
      "Epoch 343/500, Loss: 0.8168\n",
      "Epoch 344/500, Loss: 0.8158\n",
      "Epoch 345/500, Loss: 0.8148\n",
      "Epoch 346/500, Loss: 0.8138\n",
      "Epoch 347/500, Loss: 0.8128\n",
      "Epoch 348/500, Loss: 0.8118\n",
      "Epoch 349/500, Loss: 0.8108\n",
      "Epoch 350/500, Loss: 0.8098\n",
      "Epoch 351/500, Loss: 0.8088\n",
      "Epoch 352/500, Loss: 0.8079\n",
      "Epoch 353/500, Loss: 0.8069\n",
      "Epoch 354/500, Loss: 0.8059\n",
      "Epoch 355/500, Loss: 0.8049\n",
      "Epoch 356/500, Loss: 0.8039\n",
      "Epoch 357/500, Loss: 0.8030\n",
      "Epoch 358/500, Loss: 0.8020\n",
      "Epoch 359/500, Loss: 0.8010\n",
      "Epoch 360/500, Loss: 0.8000\n",
      "Epoch 361/500, Loss: 0.7991\n",
      "Epoch 362/500, Loss: 0.7981\n",
      "Epoch 363/500, Loss: 0.7972\n",
      "Epoch 364/500, Loss: 0.7962\n",
      "Epoch 365/500, Loss: 0.7952\n",
      "Epoch 366/500, Loss: 0.7943\n",
      "Epoch 367/500, Loss: 0.7933\n",
      "Epoch 368/500, Loss: 0.7924\n",
      "Epoch 369/500, Loss: 0.7914\n",
      "Epoch 370/500, Loss: 0.7905\n",
      "Epoch 371/500, Loss: 0.7895\n",
      "Epoch 372/500, Loss: 0.7886\n",
      "Epoch 373/500, Loss: 0.7877\n",
      "Epoch 374/500, Loss: 0.7867\n",
      "Epoch 375/500, Loss: 0.7858\n",
      "Epoch 376/500, Loss: 0.7849\n",
      "Epoch 377/500, Loss: 0.7839\n",
      "Epoch 378/500, Loss: 0.7830\n",
      "Epoch 379/500, Loss: 0.7821\n",
      "Epoch 380/500, Loss: 0.7811\n",
      "Epoch 381/500, Loss: 0.7802\n",
      "Epoch 382/500, Loss: 0.7793\n",
      "Epoch 383/500, Loss: 0.7784\n",
      "Epoch 384/500, Loss: 0.7775\n",
      "Epoch 385/500, Loss: 0.7765\n",
      "Epoch 386/500, Loss: 0.7756\n",
      "Epoch 387/500, Loss: 0.7747\n",
      "Epoch 388/500, Loss: 0.7738\n",
      "Epoch 389/500, Loss: 0.7729\n",
      "Epoch 390/500, Loss: 0.7720\n",
      "Epoch 391/500, Loss: 0.7711\n",
      "Epoch 392/500, Loss: 0.7702\n",
      "Epoch 393/500, Loss: 0.7693\n",
      "Epoch 394/500, Loss: 0.7684\n",
      "Epoch 395/500, Loss: 0.7675\n",
      "Epoch 396/500, Loss: 0.7666\n",
      "Epoch 397/500, Loss: 0.7657\n",
      "Epoch 398/500, Loss: 0.7648\n",
      "Epoch 399/500, Loss: 0.7639\n",
      "Epoch 400/500, Loss: 0.7630\n",
      "Epoch 401/500, Loss: 0.7622\n",
      "Epoch 402/500, Loss: 0.7613\n",
      "Epoch 403/500, Loss: 0.7604\n",
      "Epoch 404/500, Loss: 0.7595\n",
      "Epoch 405/500, Loss: 0.7587\n",
      "Epoch 406/500, Loss: 0.7578\n",
      "Epoch 407/500, Loss: 0.7569\n",
      "Epoch 408/500, Loss: 0.7560\n",
      "Epoch 409/500, Loss: 0.7552\n",
      "Epoch 410/500, Loss: 0.7543\n",
      "Epoch 411/500, Loss: 0.7535\n",
      "Epoch 412/500, Loss: 0.7526\n",
      "Epoch 413/500, Loss: 0.7517\n",
      "Epoch 414/500, Loss: 0.7509\n",
      "Epoch 415/500, Loss: 0.7500\n",
      "Epoch 416/500, Loss: 0.7492\n",
      "Epoch 417/500, Loss: 0.7483\n",
      "Epoch 418/500, Loss: 0.7475\n",
      "Epoch 419/500, Loss: 0.7466\n",
      "Epoch 420/500, Loss: 0.7458\n",
      "Epoch 421/500, Loss: 0.7449\n",
      "Epoch 422/500, Loss: 0.7441\n",
      "Epoch 423/500, Loss: 0.7433\n",
      "Epoch 424/500, Loss: 0.7424\n",
      "Epoch 425/500, Loss: 0.7416\n",
      "Epoch 426/500, Loss: 0.7407\n",
      "Epoch 427/500, Loss: 0.7399\n",
      "Epoch 428/500, Loss: 0.7391\n",
      "Epoch 429/500, Loss: 0.7383\n",
      "Epoch 430/500, Loss: 0.7374\n",
      "Epoch 431/500, Loss: 0.7366\n",
      "Epoch 432/500, Loss: 0.7358\n",
      "Epoch 433/500, Loss: 0.7350\n",
      "Epoch 434/500, Loss: 0.7341\n",
      "Epoch 435/500, Loss: 0.7333\n",
      "Epoch 436/500, Loss: 0.7325\n",
      "Epoch 437/500, Loss: 0.7317\n",
      "Epoch 438/500, Loss: 0.7309\n",
      "Epoch 439/500, Loss: 0.7301\n",
      "Epoch 440/500, Loss: 0.7293\n",
      "Epoch 441/500, Loss: 0.7284\n",
      "Epoch 442/500, Loss: 0.7276\n",
      "Epoch 443/500, Loss: 0.7268\n",
      "Epoch 444/500, Loss: 0.7260\n",
      "Epoch 445/500, Loss: 0.7252\n",
      "Epoch 446/500, Loss: 0.7245\n",
      "Epoch 447/500, Loss: 0.7237\n",
      "Epoch 448/500, Loss: 0.7229\n",
      "Epoch 449/500, Loss: 0.7221\n",
      "Epoch 450/500, Loss: 0.7213\n",
      "Epoch 451/500, Loss: 0.7205\n",
      "Epoch 452/500, Loss: 0.7197\n",
      "Epoch 453/500, Loss: 0.7189\n",
      "Epoch 454/500, Loss: 0.7182\n",
      "Epoch 455/500, Loss: 0.7174\n",
      "Epoch 456/500, Loss: 0.7166\n",
      "Epoch 457/500, Loss: 0.7158\n",
      "Epoch 458/500, Loss: 0.7150\n",
      "Epoch 459/500, Loss: 0.7143\n",
      "Epoch 460/500, Loss: 0.7135\n",
      "Epoch 461/500, Loss: 0.7127\n",
      "Epoch 462/500, Loss: 0.7120\n",
      "Epoch 463/500, Loss: 0.7112\n",
      "Epoch 464/500, Loss: 0.7104\n",
      "Epoch 465/500, Loss: 0.7097\n",
      "Epoch 466/500, Loss: 0.7089\n",
      "Epoch 467/500, Loss: 0.7081\n",
      "Epoch 468/500, Loss: 0.7074\n",
      "Epoch 469/500, Loss: 0.7066\n",
      "Epoch 470/500, Loss: 0.7058\n",
      "Epoch 471/500, Loss: 0.7051\n",
      "Epoch 472/500, Loss: 0.7043\n",
      "Epoch 473/500, Loss: 0.7036\n",
      "Epoch 474/500, Loss: 0.7028\n",
      "Epoch 475/500, Loss: 0.7021\n",
      "Epoch 476/500, Loss: 0.7013\n",
      "Epoch 477/500, Loss: 0.7006\n",
      "Epoch 478/500, Loss: 0.6999\n",
      "Epoch 479/500, Loss: 0.6991\n",
      "Epoch 480/500, Loss: 0.6984\n",
      "Epoch 481/500, Loss: 0.6976\n",
      "Epoch 482/500, Loss: 0.6969\n",
      "Epoch 483/500, Loss: 0.6962\n",
      "Epoch 484/500, Loss: 0.6954\n",
      "Epoch 485/500, Loss: 0.6947\n",
      "Epoch 486/500, Loss: 0.6940\n",
      "Epoch 487/500, Loss: 0.6932\n",
      "Epoch 488/500, Loss: 0.6925\n",
      "Epoch 489/500, Loss: 0.6918\n",
      "Epoch 490/500, Loss: 0.6911\n",
      "Epoch 491/500, Loss: 0.6903\n",
      "Epoch 492/500, Loss: 0.6896\n",
      "Epoch 493/500, Loss: 0.6889\n",
      "Epoch 494/500, Loss: 0.6882\n",
      "Epoch 495/500, Loss: 0.6874\n",
      "Epoch 496/500, Loss: 0.6867\n",
      "Epoch 497/500, Loss: 0.6860\n",
      "Epoch 498/500, Loss: 0.6853\n",
      "Epoch 499/500, Loss: 0.6846\n",
      "Epoch 500/500, Loss: 0.6839\n"
     ]
    }
   ],
   "source": [
    "train(train_data, train_lables_OH, epochs=500, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 40\n",
    "test_ele = test_data[index: index+1, :]\n",
    "plt.imshow(test_ele.reshape(28,28))\n",
    "_, y_pred = forward_pass(test_ele)\n",
    "print('Predicted value', np.argmax(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvoice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
